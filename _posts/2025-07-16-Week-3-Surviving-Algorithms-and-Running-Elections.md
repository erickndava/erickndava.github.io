---
 layout: post
 title: "Week 3: Surviving Algorithms and Running Elections"
 date: 2025-07-16T01:00:00+02:00
 categories: CS50 Data Science PGDip Journey GIS
 tags: 
 - CS50
 - C Programming
 - Spatial Science
 - PGDip
 - Learning to Code
 description: "Deciding to deep-dive into Data Science, leveraging spatial data expertise and writing about the break." 
 draft: false
--- 
Last week's [*Caesar*](https://en.wikipedia.org/wiki/Caesar_cipher) challenge pushed my schedule out by a few days and I had to pick-up pace this week, *Week 3*. Had the content been entirely new, I would have needed more time on **arrays**. This week's focus was on thinking about solving problems better, ***thinking algorithmic-ally.*** A end-of class animation comparing ***Selection Sort***, ***Bubble Sort*** and  ***Merge Sort*** was priceless, succinctly illustrating good program design and efficiency in algorithms.

| <img src="/images/run-times.PNG" alt="Run Times"/> |
|:--:|
| *Execution Time* |

This week's content was overally easy going and comprehensible. I could correctly identify and distinguish, first time, the three sorting algorithms  by analysing the run-times, *sketched on the study note above.*

While working through the Problem Set 3, the small wins really kept the morale and drive to continue high. Incorrect use of a comparison operator can be code breaking. Using a debugging technique learnt in the course, viz printing output at certain points of the code, I was able to identify the problem with my code without using the IDE's Debugging Tools.

## Wheels Off . . . Collaborate

- Problem Set 3, tasks were increasing challenging. With the first two being quick wins and quite some warm up. With the third of the problems, the tri-cycle training wheels where completely-off! One could leverage on the previous task completed but that was just the first rung of a complex ladder system.  **Programmatic and algorithmic thinking** were scaled a notch. **Two dimensional arrays** were to be employed. The *Runoff* task8I couldn't quickly crack the problem and find an approach. I had to go through the solution guide without a ready approach of my own. I learnt that it's okay to not know and it is all part of developing programmatic thinking muscle. My understanding of arrays improved as I could understand the solution easily, but getting the idea/ approach is what I lacked.

- **Pseudo-coding** really helps with the thought process and helps break down the problem into bite-sized parts. You quickly realise where functions can be employed and you're able to **abstract** as much as possible. This isolation of 'small solutions' makes the problem look much smaller and surmountable. 

- This week the training wheels are still on but the pushes and directions are became fewer and fewer. A very 'weak' framework to tackling the problem set is provided. I had a lot of **Rubber-ducking**, with *CS50 Duck Debugger* and a lot of ***Debug50*** as well. With the third task of the problem set, it took me a while to notice a *variable assignment* error which produced partially correct output. It was an exciting time debugging and similarly frustrating since I knew the code was correct, that's when the Duck really helped. 

- With a 'correct' and functioning program at hand I asked the AI to check design, ***design50***. My program worked alright but there we a number of design change suggestions. My programmatic thinking is improving. I should focus as well on **improving design**.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwMjI1NDQ4MTZdfQ==
-->